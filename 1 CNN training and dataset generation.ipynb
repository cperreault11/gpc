{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import signal\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the standard mnist dataset\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root = 'pytorch-data/',  # where to put the files\n",
    "    download = True,         # if files aren't here, download them\n",
    "    train = True,            # whether to import the test or the train subset\n",
    "    # PyTorch uses PyTorch tensors internally, not numpy arrays, so convert them.\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")\n",
    "mnist_batched = torch.utils.data.DataLoader(mnist_train, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root = 'pytorch-data/',  # where to put the files\n",
    "    download = True,         # if files aren't here, download them\n",
    "    train = False,            # whether to import the test or the train subset\n",
    "    # PyTorch uses PyTorch tensors internally, not numpy arrays, so convert them.\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interruptable class can be useful for model training\n",
    "class Interruptable():\n",
    "    class Breakout(Exception):\n",
    "        pass\n",
    "    def __init__(self):\n",
    "        self.interrupted = False\n",
    "        self.orig_handler = None\n",
    "    def __enter__(self):\n",
    "        self.orig_handler = signal.getsignal(signal.SIGINT)\n",
    "        signal.signal(signal.SIGINT, self.handle)\n",
    "        return self.check\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        signal.signal(signal.SIGINT, self.orig_handler)\n",
    "        if exc_type == Interruptable.Breakout:\n",
    "            print(' stopped')\n",
    "            return True\n",
    "        return False\n",
    "    def handle(self, signal, frame):\n",
    "        if self.interrupted:\n",
    "            self.orig_handler(signal, frame)\n",
    "        print('Interrupting ...', end='')\n",
    "        self.interrupted = True\n",
    "    def check(self):\n",
    "        if self.interrupted:\n",
    "            raise Interruptable.Breakout\n",
    "            \n",
    "def enumerate_cycle(g, shuffle=True):\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            for i,j in enumerate(np.random.permutation(len(g))):\n",
    "                yield (epoch,i), g[j]\n",
    "        else:\n",
    "            for i,x in enumerate(g):\n",
    "                yield (epoch,i), x\n",
    "        epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the classification model used in lecture\n",
    "class mnist_nn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # just need to define it the other way, and then can just return the outputs from any given layer in a similar way to classify\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop1 = nn.Dropout2d(.25)\n",
    "        self.flat = nn.Flatten(1)\n",
    "        self.lin1 = nn.Linear(9216,128)\n",
    "        self.drop2 = nn.Dropout2d(.25)\n",
    "        self.lin2 = nn.Linear(128,16)\n",
    "        self.lin3 = nn.Linear(16,10)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        # log likelihood for a batch of data\n",
    "        return - nn.functional.cross_entropy(self.f(x), y, reduction='none')\n",
    "    \n",
    "    def last_layer(self, x):\n",
    "        # computing in parts so it is easy to pull out different internal pieces\n",
    "        pooled = self.pool(nn.functional.relu(self.conv2(nn.functional.relu(self.conv1(x)))))\n",
    "        lin1 = self.lin1(self.flat(self.drop1(nn.functional.relu(pooled))))\n",
    "        lin2 = self.lin2(self.drop2(nn.functional.relu(lin1)))\n",
    "        return lin2\n",
    "\n",
    "    def f(self, x):\n",
    "        return self.lin3(nn.functional.relu(self.last_layer(x)))\n",
    "    def classify(self,x):\n",
    "        # class probabilities for a single data point\n",
    "        q = self.f(torch.as_tensor(x)[None,...])[0]\n",
    "        return nn.functional.softmax(q, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist_nn_model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
       "  (lin2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (lin3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mnist_nn_model()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.train(mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "iter_mnist = enumerate_cycle(mnist_batched, shuffle=False)\n",
    "with Interruptable() as check_interrupted:\n",
    "    for (epoch,batch_num),(imgs,lbls) in iter_mnist:\n",
    "        check_interrupted()\n",
    "        optimizer.zero_grad()\n",
    "        loglik = model(imgs, lbls)\n",
    "        e = - torch.mean(loglik)\n",
    "        e.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 25 == 0:\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            print(f'epoch={epoch} batch={batch_num}/{len(mnist_batched)} loglik={-e.item()}')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist_nn_model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
       "  (lin2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (lin3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model can be saved and loaded\n",
    "model.load_state_dict(torch.load('cnn_classifier.pt'))\n",
    "model.train(mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained CNN classifier, we need to create datasets of features and labels for all the different inputs we want to test. For now, we are only going to be working with a binary Gaussian Process classifier, so every dataset will be limited to the images that are labeled as 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features for the original MNIST dataset\n",
    "X_bin = torch.stack([img for img,lbl in mnist_train if lbl==0 or lbl ==1])\n",
    "features = model.last_layer(X_bin)\n",
    "Y_bin = [lbl for img,lbl in mnist_train if lbl == 0 or lbl == 1]\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_orig_binary.csv')\n",
    "pd.DataFrame(Y_bin).to_csv('Y_orig_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features for the test dataset\n",
    "X_bin_test = torch.stack([img for img,lbl in mnist_test if lbl == 0 or lbl == 1])\n",
    "features = model.last_layer(X_bin_test)\n",
    "Y_bin_test = [lbl for img, lbl in mnist_test if lbl == 0 or lbl == 1]\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_test_binary.csv')\n",
    "pd.DataFrame(Y_bin_test).to_csv('Y_test_binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load several noisy datasets and save the features of these datasets to a csv as well to test the Gaussian Process Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST dataset with additive white gaussian noise\n",
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-awgn.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "wn_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "wn_train_y = data['train_y']\n",
    "decoded = np.argmax(wn_train_y, axis=1)\n",
    "wn_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "wn_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(wn_train_x) if decoded[i]==0 or decoded[i]==1])\n",
    "features = model.last_layer(wn_x_bin)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_white_noise_binary.csv')\n",
    "pd.DataFrame(wn_y_bin).to_csv('Y_white_noise_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset with motion blur\n",
    "\n",
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-motion-blur.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    mb_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "    mb_train_y = data['train_y']\n",
    "    decoded = np.argmax(mb_train_y, axis=1)\n",
    "    mb_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "    mb_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(mb_train_x) if decoded[i]==0 or decoded[i]==1])\n",
    "features = model.last_layer(mb_x_bin)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_motion_blur_binary.csv')\n",
    "pd.DataFrame(mb_y_bin).to_csv('Y_motion_blur_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset with reduced contrast and added white gaussian noise\n",
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-reduced-contrast-and-awgn.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    rc_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "    rc_train_y = data['train_y']\n",
    "    decoded = np.argmax(rc_train_y, axis=1)\n",
    "    rc_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "    rc_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(rc_train_x) if decoded[i]==0 or decoded[i]==1])\n",
    "features = model.last_layer(rc_x_bin)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_reduced_contrast_binary.csv')\n",
    "pd.DataFrame(rc_y_bin).to_csv('Y_reduced_contrast_binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final binary datasets we will test on, we create new data by using adversarial attacks. These attacks take an input image and distort it in a way that attempts to make the CNN classifier produce outputs that are as different as possible from the original outputs. This technique often makes adversarial examples successful at 'confusing' neural network classifiers, so it will be interesting to see if a Gaussian Process classifier can recognize these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also generate adversarial examples with varying amounts of noise to demonstrate how well our Gaussian Process classifier can handle different levels of adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fgm_10 = fast_gradient_method(model.f, X_bin,.1,np.inf)\n",
    "features = model.last_layer(X_fgm_10)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_fgm_10_binary.csv')\n",
    "pd.DataFrame(Y_bin).to_csv('Y_fgm_10_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fgm_25 = fast_gradient_method(model.f, X_bin[:5000],.25,np.inf)\n",
    "features = model.last_layer(X_fgm_25)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_fgm_25_binary.csv')\n",
    "pd.DataFrame(Y_bin[:5000]).to_csv('Y_fgm_25_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fgm_50 = fast_gradient_method(model.f, X_bin[:5000],.5,np.inf)\n",
    "features = model.last_layer(X_fgm_50)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_fgm_50_binary.csv')\n",
    "pd.DataFrame(Y_bin[:5000]).to_csv('Y_fgm_50_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fgm_100 = fast_gradient_method(model.f, X_bin[:5000],1,np.inf)\n",
    "features = model.last_layer(X_fgm_100)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_fgm_100_binary.csv')\n",
    "pd.DataFrame(Y_bin[:5000]).to_csv('Y_fgm_100_binary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the projected gradient descent method, it can take a long time to generate adversarial examples. To limit processing time, we'll only generate a few thousand examples for every noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pgd_10 = projected_gradient_descent(model.f, X_bin[:1500], .1,.01, 40, np.inf)\n",
    "features = model.last_layer(X_pgd_10)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_pgd_10_binary.csv')\n",
    "pd.DataFrame(Y_bin[:1500]).to_csv('Y_pgd_10_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pgd_25 = projected_gradient_descent(model.f, X_bin[:1500], .25,.01, 40, np.inf)\n",
    "features = model.last_layer(X_pgd_25)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_pgd_25_binary.csv')\n",
    "pd.DataFrame(Y_bin[:1500]).to_csv('Y_pgd_25_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pgd_50 = projected_gradient_descent(model.f, X_bin[:1500], .5,.01, 40, np.inf)\n",
    "features = model.last_layer(X_pgd_50)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_pgd_50_binary.csv')\n",
    "pd.DataFrame(Y_bin[:1500]).to_csv('Y_pgd_50_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pgd_100 = projected_gradient_descent(model.f, X_bin[:1500], 1,.01, 40, np.inf)\n",
    "features = model.last_layer(X_pgd_100)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_pgd_100_binary.csv')\n",
    "pd.DataFrame(Y_bin[:1500]).to_csv('Y_pgd_100_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fgm_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_fgm_10,'X_fgm_10_images.pt')\n",
    "torch.save(X_fgm_25,'X_fgm_25_images.pt')\n",
    "torch.save(X_fgm_50,'X_fgm_50_images.pt')\n",
    "torch.save(X_fgm_100,'X_fgm_100_images.pt')\n",
    "torch.save(X_pgd_10,'X_pgd_10_images.pt')\n",
    "torch.save(X_pgd_25,'X_pgd_25_images.pt')\n",
    "torch.save(X_pgd_50,'X_pgd_50_images.pt')\n",
    "torch.save(X_pgd_100,'X_pgd_100_images.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
