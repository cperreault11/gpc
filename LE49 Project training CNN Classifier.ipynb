{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a881517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in coregionalize: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import GPy as gp\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import signal\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a87deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the standard mnist dataset\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root = 'pytorch-data/',  # where to put the files\n",
    "    download = True,         # if files aren't here, download them\n",
    "    train = True,            # whether to import the test or the train subset\n",
    "    # PyTorch uses PyTorch tensors internally, not numpy arrays, so convert them.\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")\n",
    "mnist_batched = torch.utils.data.DataLoader(mnist_train, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747afcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interruptable class can be useful for model training\n",
    "class Interruptable():\n",
    "    class Breakout(Exception):\n",
    "        pass\n",
    "    def __init__(self):\n",
    "        self.interrupted = False\n",
    "        self.orig_handler = None\n",
    "    def __enter__(self):\n",
    "        self.orig_handler = signal.getsignal(signal.SIGINT)\n",
    "        signal.signal(signal.SIGINT, self.handle)\n",
    "        return self.check\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        signal.signal(signal.SIGINT, self.orig_handler)\n",
    "        if exc_type == Interruptable.Breakout:\n",
    "            print(' stopped')\n",
    "            return True\n",
    "        return False\n",
    "    def handle(self, signal, frame):\n",
    "        if self.interrupted:\n",
    "            self.orig_handler(signal, frame)\n",
    "        print('Interrupting ...', end='')\n",
    "        self.interrupted = True\n",
    "    def check(self):\n",
    "        if self.interrupted:\n",
    "            raise Interruptable.Breakout\n",
    "            \n",
    "def enumerate_cycle(g, shuffle=True):\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            for i,j in enumerate(np.random.permutation(len(g))):\n",
    "                yield (epoch,i), g[j]\n",
    "        else:\n",
    "            for i,x in enumerate(g):\n",
    "                yield (epoch,i), x\n",
    "        epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297e6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the classification model used in lecture\n",
    "class mnist_nn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # just need to define it the other way, and then can just return the outputs from any given layer in a similar way to classify\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.drop1 = nn.Dropout2d(.25)\n",
    "        self.flat = nn.Flatten(1)\n",
    "        self.lin1 = nn.Linear(9216,128)\n",
    "        self.drop2 = nn.Dropout2d(.25)\n",
    "        self.lin2 = nn.Linear(128,16)\n",
    "        self.lin3 = nn.Linear(16,10)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        # log likelihood for a batch of data\n",
    "        return - nn.functional.cross_entropy(self.f(x), y, reduction='none')\n",
    "    \n",
    "    def last_layer(self, x):\n",
    "        # computing in parts so it is easy to pull out different internal pieces\n",
    "        pooled = self.pool(nn.functional.relu(self.conv2(nn.functional.relu(self.conv1(x)))))\n",
    "        lin1 = self.lin1(self.flat(self.drop1(nn.functional.relu(pooled))))\n",
    "        lin2 = self.lin2(self.drop2(nn.functional.relu(lin1)))\n",
    "        return lin2\n",
    "    \n",
    "    def f(self, x):\n",
    "        return self.lin3(nn.functional.relu(self.last_layer(x)))\n",
    "    def classify(self,x):\n",
    "        # class probabilities for a single data point\n",
    "        q = self.f(torch.as_tensor(x)[None,...])[0]\n",
    "        return nn.functional.softmax(q, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d4be6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist_nn_model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
       "  (lin2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (lin3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mnist_nn_model()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.train(mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35b4a396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8 batch=475/600 loglik=-0.013399560004472733\n",
      "Interrupting ... stopped\n"
     ]
    }
   ],
   "source": [
    "iter_mnist = enumerate_cycle(mnist_batched, shuffle=False)\n",
    "with Interruptable() as check_interrupted:\n",
    "    for (epoch,batch_num),(imgs,lbls) in iter_mnist:\n",
    "        check_interrupted()\n",
    "        optimizer.zero_grad()\n",
    "        loglik = model(imgs, lbls)\n",
    "        e = - torch.mean(loglik)\n",
    "        e.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 25 == 0:\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            print(f'epoch={epoch} batch={batch_num}/{len(mnist_batched)} loglik={-e.item()}')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9a6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('cnn_classifier.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef58b2f",
   "metadata": {},
   "source": [
    "Might be a good idea to try to figure out the maximum loglikelihood at some point. Not really sure how I would do this, but it usually seems to be a good idea in this class. I kinda want to just guess it's zero but who knows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "326a6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed604d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist_nn_model(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
       "  (lin2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (lin3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a899c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = torch.stack([img for img,lbl in mnist_train if lbl==0 or lbl ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49bc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.last_layer(X_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14328ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_bin = [lbl for img,lbl in mnist_train if lbl == 0 or lbl == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fd7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary.csv')\n",
    "pd.DataFrame(Y_bin).to_csv('Y_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8bd0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.detach().numpy()\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe316344",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_577/1044132212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69d0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all of these features to a csv file, however that's gonna require internet of some type. Once I have all that, this notebook should be done.\n",
    "# this will be a binary dataset first of features (should have 16) and the label either 0 or 1. \n",
    "# still need to consider if it's better to do this all based on the last layer (that sigmoid layer is applied to), or the last \"feature\" layer right above that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "996ec1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8360f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-awgn.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7105e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "wn_train_y = data['train_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d611c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = np.argmax(wn_train_y, axis=1)\n",
    "wn_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "wn_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(wn_train_x) if decoded[i]==0 or decoded[i]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f94f364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.last_layer(wn_x_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1b5748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary_wn.csv')\n",
    "pd.DataFrame(wn_y_bin).to_csv('Y_binary_wn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a2b7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-motion-blur.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    mb_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "    mb_train_y = data['train_y']\n",
    "    decoded = np.argmax(mb_train_y, axis=1)\n",
    "    mb_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "    mb_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(mb_train_x) if decoded[i]==0 or decoded[i]==1])\n",
    "features = model.last_layer(mb_x_bin)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary_mb.csv')\n",
    "pd.DataFrame(mb_y_bin).to_csv('Y_binary_mb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f036b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/nmnist/mnist-with-reduced-contrast-and-awgn.mat\")\n",
    "\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    rc_train_x = data['train_x'].reshape(60000,1,28,28)\n",
    "    rc_train_y = data['train_y']\n",
    "    decoded = np.argmax(rc_train_y, axis=1)\n",
    "    rc_y_bin = np.array([lbl for lbl in decoded if lbl == 0 or lbl == 1])\n",
    "    rc_x_bin = torch.stack([torch.Tensor(img)/255 for i,img in enumerate(rc_train_x) if decoded[i]==0 or decoded[i]==1])\n",
    "features = model.last_layer(rc_x_bin)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary_rc.csv')\n",
    "pd.DataFrame(rc_y_bin).to_csv('Y_binary_rc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f19c05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.last_layer(X_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f093ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bin[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1456a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from absl import app, flags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9dfe92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pgd = projected_gradient_descent(model.f, X_bin[:1000], .2, .01, 40, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a1a29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.last_layer(X_pgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77a4771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary_pgd.csv')\n",
    "pd.DataFrame(Y_bin[:1000]).to_csv('Y_binary_pgd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cf745aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fgm = fast_gradient_method(model.f, X_bin[:1000], .2, np.inf)\n",
    "features = model.last_layer(X_fgm)\n",
    "pd.DataFrame(features.detach().numpy()).to_csv('X_binary_fgm.csv')\n",
    "pd.DataFrame(Y_bin[:1000]).to_csv('Y_binary_fgm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96210f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
